"""
===========================================
ESTUDO GUIADO LANGGRAPH - PARTE 2
Agente Real com LLM e Ferramentas
===========================================

Agora vamos criar um AGENTE DE VERDADE que:
- Usa um LLM real (OpenAI/Anthropic) para pensar
- Decide automaticamente quais ferramentas usar
- Executa m√∫ltiplas a√ß√µes em sequ√™ncia
- Mant√©m contexto da conversa

Este √© o padr√£o que voc√™ usar√° em 90% dos casos reais!
"""

import os
from typing import TypedDict, Annotated, Sequence
from langgraph.graph import StateGraph, END
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
import operator


# ===================================================================
# PARTE 1: DEFINIR FERRAMENTAS (TOOLS)
# ===================================================================
print("\n" + "="*70)
print("PARTE 1: Criando Ferramentas para o Agente")
print("="*70)

@tool
def calculadora(expressao: str) -> str:
    """
    Calcula express√µes matem√°ticas simples.

    Args:
        expressao: A express√£o matem√°tica (ex: "2 + 2", "10 * 5")
    """
    try:
        # ATEN√á√ÉO: Em produ√ß√£o, use uma biblioteca segura!
        resultado = eval(expressao)
        print(f"üî¢ [TOOL: calculadora] Calculando '{expressao}' = {resultado}")
        return f"Resultado: {resultado}"
    except Exception as e:
        return f"Erro ao calcular: {e}"


@tool
def buscar_clima(cidade: str) -> str:
    """
    Busca informa√ß√µes de clima para uma cidade.

    Args:
        cidade: Nome da cidade
    """
    # Simulando API de clima
    print(f"üå§Ô∏è  [TOOL: buscar_clima] Consultando clima de {cidade}...")

    climas_fake = {
        "s√£o paulo": "25¬∞C, parcialmente nublado",
        "rio de janeiro": "30¬∞C, ensolarado",
        "bras√≠lia": "28¬∞C, c√©u limpo",
    }

    resultado = climas_fake.get(cidade.lower(), "22¬∞C, clima agrad√°vel")
    return f"Clima em {cidade}: {resultado}"


@tool
def buscar_na_web(query: str) -> str:
    """
    Busca informa√ß√µes na internet.

    Args:
        query: Termo de busca
    """
    print(f"üîç [TOOL: buscar_na_web] Buscando '{query}'...")

    # Simulando resultados de busca
    resultados_fake = {
        "python": "Python √© uma linguagem de programa√ß√£o de alto n√≠vel, interpretada...",
        "langgraph": "LangGraph √© uma biblioteca para construir agentes de IA stateful...",
        "default": f"Informa√ß√µes sobre '{query}': [simula√ß√£o de resultados da web]"
    }

    for key in resultados_fake:
        if key in query.lower():
            return resultados_fake[key]

    return resultados_fake["default"]


# Lista de todas as ferramentas dispon√≠veis
ferramentas = [calculadora, buscar_clima, buscar_na_web]

print("\n‚úÖ Ferramentas criadas:")
for f in ferramentas:
    print(f"   - {f.name}: {f.description}")


# ===================================================================
# PARTE 2: DEFINIR O ESTADO DO AGENTE
# ===================================================================
print("\n" + "="*70)
print("PARTE 2: Definindo o Estado do Agente")
print("="*70)

class EstadoAgente(TypedDict):
    """
    Estado que mant√©m toda a conversa e contexto do agente.

    - mensagens: Hist√≥rico completo (humano, AI, ferramentas)
    - iteracoes: Contador de itera√ß√µes (evita loops infinitos)
    """
    mensagens: Annotated[Sequence[BaseMessage], operator.add]
    iteracoes: int


# ===================================================================
# PARTE 3: N√ì QUE CHAMA O LLM
# ===================================================================
print("\n" + "="*70)
print("PARTE 3: Criando o N√≥ de Racioc√≠nio (LLM)")
print("="*70)

def no_agente(estado: EstadoAgente):
    """
    Este √© o C√âREBRO do agente.
    O LLM analisa a conversa e decide:
    1. Usar uma ferramenta, OU
    2. Responder diretamente ao usu√°rio
    """
    print(f"\nüß† [AGENTE] Pensando... (itera√ß√£o {estado.get('iteracoes', 0)})")

    # Inicializar o LLM com as ferramentas
    # NOTA: Voc√™ precisa ter OPENAI_API_KEY no .env
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    llm_com_tools = llm.bind_tools(ferramentas)

    # LLM analisa todas as mensagens e decide o que fazer
    resposta = llm_com_tools.invoke(estado["mensagens"])

    # Verificar se o LLM quer usar ferramentas
    if resposta.tool_calls:
        print(f"   üéØ Decis√£o: Usar ferramenta '{resposta.tool_calls[0]['name']}'")
    else:
        print(f"   üí¨ Decis√£o: Responder diretamente")

    return {
        "mensagens": [resposta],
        "iteracoes": estado.get("iteracoes", 0) + 1
    }


# ===================================================================
# PARTE 4: N√ì QUE EXECUTA FERRAMENTAS
# ===================================================================
print("\n" + "="*70)
print("PARTE 4: Criando o N√≥ de A√ß√£o (Execu√ß√£o de Tools)")
print("="*70)

def no_ferramentas(estado: EstadoAgente):
    """
    Executa as ferramentas que o LLM decidiu usar.
    """
    print(f"\n‚ö° [FERRAMENTAS] Executando a√ß√µes...")

    ultima_mensagem = estado["mensagens"][-1]

    # Executar cada ferramenta solicitada
    resultados = []
    for tool_call in ultima_mensagem.tool_calls:
        # Encontrar a ferramenta correspondente
        ferramenta = next((f for f in ferramentas if f.name == tool_call["name"]), None)

        if ferramenta:
            # Executar a ferramenta
            resultado = ferramenta.invoke(tool_call["args"])

            # Criar mensagem com o resultado
            resultados.append(
                ToolMessage(
                    content=str(resultado),
                    tool_call_id=tool_call["id"]
                )
            )

    return {"mensagens": resultados}


# ===================================================================
# PARTE 5: FUN√á√ÉO DE ROTEAMENTO (DECIDIR PR√ìXIMO PASSO)
# ===================================================================
print("\n" + "="*70)
print("PARTE 5: Criando L√≥gica de Roteamento")
print("="*70)

def should_continue(estado: EstadoAgente) -> str:
    """
    Decide se o agente deve:
    - Continuar (executar ferramentas)
    - Terminar (j√° respondeu ao usu√°rio)
    """
    ultima_mensagem = estado["mensagens"][-1]
    iteracoes = estado.get("iteracoes", 0)

    # Seguran√ßa: limite de itera√ß√µes
    if iteracoes > 10:
        print("   ‚ö†Ô∏è  Limite de itera√ß√µes atingido")
        return "end"

    # Se o LLM chamou ferramentas, continuar
    if hasattr(ultima_mensagem, "tool_calls") and ultima_mensagem.tool_calls:
        print("   ‚û°Ô∏è  Roteamento: Executar ferramentas")
        return "continue"

    # Caso contr√°rio, terminar
    print("   ‚úÖ Roteamento: Finalizar")
    return "end"


# ===================================================================
# PARTE 6: CONSTRUIR O GRAFO DO AGENTE
# ===================================================================
print("\n" + "="*70)
print("PARTE 6: Montando o Grafo do Agente")
print("="*70)

def criar_agente():
    """
    Cria o grafo completo do agente ReAct.

    Fluxo:
    1. START ‚Üí agente (LLM pensa e decide)
    2. Se decidiu usar ferramenta ‚Üí ferramentas ‚Üí volta para agente
    3. Se decidiu responder ‚Üí END
    """
    workflow = StateGraph(EstadoAgente)

    # Adicionar n√≥s
    workflow.add_node("agente", no_agente)
    workflow.add_node("ferramentas", no_ferramentas)

    # Ponto de entrada
    workflow.set_entry_point("agente")

    # Roteamento condicional
    workflow.add_conditional_edges(
        "agente",
        should_continue,
        {
            "continue": "ferramentas",
            "end": END
        }
    )

    # Depois de executar ferramentas, volta para o agente pensar novamente
    workflow.add_edge("ferramentas", "agente")

    return workflow.compile()


print("\n‚úÖ Grafo do agente constru√≠do!")
print("""
Fluxo do agente:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  START  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ AGENTE  ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  (LLM)  ‚îÇ        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
     ‚îÇ             ‚îÇ
     ‚ñº             ‚îÇ
  Precisa         ‚îÇ
ferramenta?       ‚îÇ
     ‚îÇ             ‚îÇ
  ‚îå‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îê         ‚îÇ
  ‚îÇ SIM ‚îÇ N√ÉO     ‚îÇ
  ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò  ‚îÇ      ‚îÇ
     ‚îÇ     ‚ñº      ‚îÇ
     ‚îÇ   [END]    ‚îÇ
     ‚îÇ            ‚îÇ
     ‚ñº            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇFERRAMENTAS‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
""")


# ===================================================================
# PARTE 7: TESTAR O AGENTE
# ===================================================================
if __name__ == "__main__":
    print("\n\n" + "="*70)
    print("PARTE 7: TESTANDO O AGENTE")
    print("="*70)

    # Verificar se tem API key
    if not os.getenv("OPENAI_API_KEY"):
        print("\n‚ö†Ô∏è  ATEN√á√ÉO: Configure OPENAI_API_KEY no arquivo .env")
        print("   Sem a chave, o agente n√£o funcionar√°.\n")
        exit(1)

    agente = criar_agente()

    # Testes
    testes = [
        "Qual o clima em S√£o Paulo?",
        "Quanto √© 25 * 4 + 10?",
        "Me explique o que √© LangGraph",
        "Qual o clima no Rio e quanto √© 100 dividido por 5?",  # M√∫ltiplas ferramentas!
    ]

    for i, pergunta in enumerate(testes, 1):
        print(f"\n{'='*70}")
        print(f"üß™ TESTE {i}: {pergunta}")
        print(f"{'='*70}")

        resultado = agente.invoke({
            "mensagens": [HumanMessage(content=pergunta)],
            "iteracoes": 0
        })

        # Mostrar a resposta final
        print(f"\nüí¨ RESPOSTA FINAL:")
        resposta_final = resultado["mensagens"][-1]
        if hasattr(resposta_final, "content"):
            print(f"   {resposta_final.content}")

        print(f"\nüìä Total de itera√ß√µes: {resultado['iteracoes']}")
        print(f"üìä Total de mensagens: {len(resultado['mensagens'])}")


# ===================================================================
# RESUMO E PR√ìXIMOS PASSOS
# ===================================================================
print("\n\n" + "="*70)
print("üìö RESUMO - O QUE VOC√ä APRENDEU")
print("="*70)
print("""
‚úÖ Como criar um agente REAL com LLM:
   - Definir ferramentas com @tool decorator
   - Bind ferramentas ao LLM com .bind_tools()
   - LLM decide automaticamente quais ferramentas usar

‚úÖ Padr√£o ReAct em a√ß√£o:
   AGENTE (pensa) ‚Üí decide ferramenta ‚Üí FERRAMENTAS (executa)
   ‚Üí volta para AGENTE ‚Üí decide responder ‚Üí END

‚úÖ Tool calling:
   - LLM retorna tool_calls quando quer usar ferramenta
   - Executamos a ferramenta e devolvemos ToolMessage
   - LLM v√™ o resultado e decide pr√≥ximo passo

‚úÖ Roteamento condicional:
   - should_continue decide se continua ou termina
   - Permite loops (ReAct) com seguran√ßa (limite de itera√ß√µes)

üéØ PR√ìXIMO PASSO: 03_agente_conversacional.py
   - Adicionar mem√≥ria persistente
   - Manter contexto entre m√∫ltiplas conversas
   - Implementar checkpoints para salvar estado
""")

print("\n" + "="*70)
print("üí° EXERC√çCIO")
print("="*70)
print("""
Adicione uma nova ferramenta ao agente:

@tool
def converter_moeda(valor: float, de: str, para: str) -> str:
    \"\"\"Converte valores entre moedas\"\"\"
    # Implemente convers√£o simulada
    pass

Teste com: "Quanto √© 100 d√≥lares em reais?"
""")
